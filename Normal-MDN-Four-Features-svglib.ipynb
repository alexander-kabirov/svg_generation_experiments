{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<svg width=\"300\" height=\"100\" xmlns=\"http://www.w3.org/2000/svg\">\n",
    "<line x1=\"10\" y1=\"10\" x2=\"290\" y2=\"10\" style=\"stroke:#000\">\n",
    "</line>\n",
    "<ellipse cx=\"150\" cy=\"50\" rx=\"20\" ry=\"20\" style=\"stroke:#000;fill:none;\"></ellipse>\n",
    "</svg>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "import svgwrite\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import warnings\n",
    "import cmath\n",
    "from svgpathtools import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsvg.svglib.svg import SVG\n",
    "from deepsvg.difflib.tensor import SVGTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda0 = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, attributes, svg_attributes = svg2paths2('Minisample/leaves.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = []\n",
    "for path in paths:\n",
    "    wsvg(path,filename='temp_plant.svg')\n",
    "    plant = SVG.load_svg('temp_plant.svg')\n",
    "    plant.normalize()\n",
    "    plant.canonicalize()\n",
    "    #plant.simplify_heuristic()\n",
    "    tensor = SVGTensor.from_data(plant.copy().numericalize().to_tensor())\n",
    "    print(tensor.data)\n",
    "    tensor.pad(47)\n",
    "    tensor.add_sos()\n",
    "    cat_tensor = torch.cat((tensor.control1,tensor.control2,tensor.end_pos),1).unsqueeze(0)\n",
    "    print(cat_tensor.shape)\n",
    "    figures.append(cat_tensor)                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Idea: first convert to the line format according to the necessary #of points and then split evenly (smallest element)\n",
    "##### Hierarchical generation - first generate the structure and then indicidual item\n",
    "##### conceptual learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = figures[:,:-1,:]\n",
    "y = figures[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batches = torch.split(x,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batches = torch.split(y,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMArtist(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, mix_k, num_layers=2,dropout=0.1): #, dropout=0.1\n",
    "        super(LSTMArtist, self).__init__()\n",
    "        \n",
    "        #self.cov = torch.eye(6)\n",
    "        #self.cov.requires_grad = True\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim,num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        self.linear_mu = nn.Linear(hidden_dim,mix_k*6)\n",
    "        self.linear_sigmasq = nn.Linear(hidden_dim,1)\n",
    "        self.linear_mix = nn.Linear(hidden_dim,mix_k)\n",
    "        \n",
    "        self.activation = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        coordinates_mu = self.linear_mu(lstm_out) #remove exp in case of delta\n",
    "        coordinates_sigmasq = torch.exp(self.linear_sigmasq(lstm_out)) #torch.exp self.relu\n",
    "        coordinates_mix = self.softmax(self.linear_mix(lstm_out))\n",
    "        return (coordinates_mu,coordinates_sigmasq,coordinates_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(x, mu, sigmasq):\n",
    "    # NOTE: we could use the new `torch.distributions` package for this now\n",
    "    #print((-1/(2*sigmasq))* torch.norm((x-mu), 2, 2)**2)\n",
    "    #print(torch.exp((-1/(2*sigmasq))* torch.norm((x-mu), 2, 2)**2))\n",
    "    pdf = (1/torch.sqrt(2*np.pi*sigmasq)) * torch.exp(torch.min(torch.tensor(50).to(cuda0),torch.max(torch.tensor(-50).to(cuda0),(-1/(2*sigmasq))* torch.norm((x-mu), 2, 2)**2)))\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(coordinates_mu,coordinates_sigmasq,coordinates_mix,k,y):\n",
    "    losses = torch.zeros(y.shape[0:2],device = cuda0)\n",
    "    for i in range(k):  # To Do: put k versions for method and absolute, add loss proportionally likelihood\n",
    "        likelihood_z_x = gaussian_pdf(y, coordinates_mu[:,:,i*6:(i+1)*6], coordinates_sigmasq[:,:, 0])\n",
    "        #print(likelihood_z_x)\n",
    "        losses += coordinates_mix[:,:,i] * likelihood_z_x\n",
    "    return torch.mean(-(torch.log(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30\n",
    "model = LSTMArtist(6,400,k,dropout=0.2,num_layers=2).to(cuda0) #.to(cuda0) ,dropout=0.9\n",
    "##################\n",
    "#mse_loss = nn.MSELoss()\n",
    "lr = 0.5 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "#################\n",
    "for epoch in range(20000):\n",
    "    if epoch % 1000 == 0:\n",
    "        print(\"Running epoch\",epoch)\n",
    "    total_loss = 0\n",
    "    for i,batch in enumerate(x_batches):\n",
    "        optimizer.zero_grad()\n",
    "        coordinates_mu,coordinates_sigmasq,coordinates_mix = model(batch)\n",
    "        #print(coordinates_sigmasq)\n",
    "        loss = calculate_loss(coordinates_mu,coordinates_sigmasq,coordinates_mix,k,y_batches[i])\n",
    "        #print(\">>>>>>>>>>>>>>>>>>>\",losses)\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 1) #what param to set here? (grads are exploding without cliping)\n",
    "        optimizer.step()\n",
    "        #print(output.size())\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 1000 == 0:\n",
    "        print(total_loss) #with 10 epochs 7720 2.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_MDM_MULti.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample(coordinates_mu,coordinates_sigmasq,coordinates_mix):\n",
    "    with torch.no_grad():\n",
    "        #coordinates_mu = coordinates_mu.cpu()\n",
    "        #coordinates_sigmasq = coordinates_sigmasq.cpu()\n",
    "        #coordinates_mix = coordinates_mix.cpu()\n",
    "\n",
    "        mix_dist = Categorical(coordinates_mix[0,0,:])\n",
    "        mix_index = mix_dist.sample()\n",
    "        mu = coordinates_mu[0,0,mix_index*2:(mix_index+1)*2]\n",
    "        sigma = torch.sqrt(coordinates_sigmasq)\n",
    "        #sigma = torch.tensor([[[0.00001]]],device=cuda0)\n",
    "        angle = Normal(mu, sigma).sample()\n",
    "        #print(str_key,absolute,coordinates)\n",
    "        return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the picture from the trained model\n",
    "def generate_vectors(model,start_vector,iterations):\n",
    "    vectors = start_vector\n",
    "    for i in range(iterations):\n",
    "        coordinates_mu,coordinates_sigmasq,coordinates_mix = model(vectors)\n",
    "        angle = random_sample(coordinates_mu[:,-1:,:],coordinates_sigmasq[:,-1:,:],coordinates_mix[:,-1:,:])\n",
    "        vectors = torch.cat((vectors,angle),1)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_vector = torch.tensor([[[0.0,0.0]]],device=cuda0)\n",
    "vectors = generate_vectors(model,start_vector,160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_values = torch.tensor([[0.0,0.0]],device=cuda0)\n",
    "for i in range(1,vectors.shape[1]):\n",
    "    real_values= torch.cat((real_values,torch.unsqueeze(real_values[-1]+vectors[0,i,:],0)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments =[]\n",
    "for i in range(1,real_values.shape[0]):   \n",
    "        segments.append(Line(complex(real_values[i-1,0],real_values[i-1,1]),complex(real_values[i,0],real_values[i,1])))\n",
    "segments.append(Line(complex(real_values[i,0],real_values[i,1]),complex()))\n",
    "wsvg(segments,filename='test_algo_8.svg') #nodes=[complex(),complex(real_values[real_values.shape[0]-1,0],real_values[real_values.shape[0]-1,1])],\n",
    "SVG('test_algo_8.svg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
