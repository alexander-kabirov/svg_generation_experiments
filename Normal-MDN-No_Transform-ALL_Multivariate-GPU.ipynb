{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<svg width=\"300\" height=\"100\" xmlns=\"http://www.w3.org/2000/svg\">\n",
    "<line x1=\"10\" y1=\"10\" x2=\"290\" y2=\"10\" style=\"stroke:#000\">\n",
    "</line>\n",
    "<ellipse cx=\"150\" cy=\"50\" rx=\"20\" ry=\"20\" style=\"stroke:#000;fill:none;\"></ellipse>\n",
    "</svg>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "import svgwrite\n",
    "from xml.dom import minidom\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_path(path,output,start=[None,None],last_key=None,offset=[0,0],first_run=True):\n",
    "    while len(path) > 0:\n",
    "        key = path.pop(0)\n",
    "        if key == 'm':\n",
    "            if first_run:\n",
    "                start = list(map(float,path.pop(0).split(',')))\n",
    "                x,y = 0 + offset[0], 0 + offset[1]\n",
    "                first_run=False\n",
    "            else:\n",
    "                x,y = list(map(float,path.pop(0).split(',')))\n",
    "            output.append(['m',0,x,y,0,0,0,0])\n",
    "            last_key = \"m\"\n",
    "        elif key == 'M':\n",
    "            if first_run:\n",
    "                start = list(map(float,path.pop(0).split(',')))\n",
    "                x,y = 0 + offset[0],0 + offset[1]\n",
    "                first_run=False\n",
    "            else:\n",
    "                x,y = list(map(float,path.pop(0).split(',')))\n",
    "                x = x- start[0] + offset[0]\n",
    "                y = y- start[1] + offset[1]\n",
    "            output.append(['m',1,x,y,0,0,0,0])\n",
    "            last_key = \"M\"\n",
    "        elif key == 'c':\n",
    "            x1,y1 = list(map(float,path.pop(0).split(',')))\n",
    "            x2,y2 = list(map(float,path.pop(0).split(',')))\n",
    "            x,y = list(map(float,path.pop(0).split(',')))\n",
    "            output.append(['c',0,x1,y1,x2,y2,x,y])\n",
    "            last_key = \"c\"\n",
    "        elif key == 'C':\n",
    "            x1,y1 = list(map(float,path.pop(0).split(',')))\n",
    "            x1 = x1 - start[0] + offset[0]\n",
    "            y1 = y1 - start[1] + offset[1]\n",
    "            x2,y2 = list(map(float,path.pop(0).split(',')))\n",
    "            x2 = x2 - start[0] + offset[0]\n",
    "            y2 = y2 - start[1] + offset[1]\n",
    "            x,y = list(map(float,path.pop(0).split(',')))\n",
    "            x = x - start[0] + offset[0]\n",
    "            y = y - start[1] + offset[1]\n",
    "            output.append(['c',1,x1,y1,x2,y2,x,y])\n",
    "            last_key = \"C\"\n",
    "        elif key == 'z' or key == 'Z':\n",
    "            output.append(['z',0,0,0,0,0,0,0])\n",
    "            last_key = \"z\"\n",
    "        elif key == 'l':\n",
    "            x,y = list(map(float,path.pop(0).split(',')))\n",
    "            output.append(['l',0,x,y,0,0,0,0])\n",
    "            last_key = \"l\"\n",
    "        elif key == 'L':\n",
    "            x,y = list(map(float,path.pop(0).split(',')))\n",
    "            x = x - start[0] + offset[0]\n",
    "            y = y - start[1] + offset[1]\n",
    "            output.append(['l',1,x,y,0,0,0,0])\n",
    "            last_key = \"L\"\n",
    "        elif key == 'h':\n",
    "            x = float(path.pop(0))\n",
    "            output.append(['l',0,x,0,0,0,0,0]) #l is ententionally put here to minimize the # of commands \n",
    "            last_key = \"h\"\n",
    "        elif key == 'H':\n",
    "            x = float(path.pop(0))\n",
    "            x = x - start[0] + offset[0]\n",
    "            output.append(['l',1,x,0,0,0,0,0]) #l is ententionally put here to minimize the # of commands\n",
    "            last_key = \"H\"\n",
    "        elif key == 'v':\n",
    "            y = float(path.pop(0))\n",
    "            output.append(['l',0,0,y,0,0,0,0]) #l is ententionally put here to minimize the # of commands\n",
    "            last_key = \"v\"\n",
    "        elif key == 'V':\n",
    "            y = float(path.pop(0))\n",
    "            y = y - start[1] + offset[1]\n",
    "            output.append(['l',1,0,y,0,0,0,0]) #l is ententionally put here to minimize the # of commands \n",
    "            last_key = \"V\"\n",
    "        else:\n",
    "            if last_key == 'c':\n",
    "                x1,y1 = list(map(float,key.split(',')))\n",
    "                x2,y2 = list(map(float,path.pop(0).split(',')))\n",
    "                x,y = list(map(float,path.pop(0).split(',')))\n",
    "                output.append(['c',0,x1,y1,x2,y2,x,y])\n",
    "                last_key = \"c\"\n",
    "            elif last_key == 'C':\n",
    "                x1,y1 = list(map(float,key.split(',')))\n",
    "                x1 = x1 - start[0] + offset[0]\n",
    "                y1 = y1 - start[1] + offset[1]\n",
    "                x2,y2 = list(map(float,path.pop(0).split(',')))\n",
    "                x2 = x2 - start[0] + offset[0]\n",
    "                y2 = y2 - start[1] + offset[1]\n",
    "                x,y = list(map(float,path.pop(0).split(',')))\n",
    "                x = x - start[0] + offset[0]\n",
    "                y = y - start[1] + offset[1]\n",
    "                output.append(['c',1,x1,y1,x2,y2,x,y])\n",
    "                last_key = \"C\"\n",
    "            elif last_key == 'm':\n",
    "                x,y = list(map(float,key.split(',')))\n",
    "                output.append(['m',0,x,y,0,0,0,0])\n",
    "                last_key = \"m\"\n",
    "            elif last_key == 'M':\n",
    "                x,y = list(map(float,key.split(',')))\n",
    "                x = x- start[0] + offset[0]\n",
    "                y = y- start[1] + offset[1]\n",
    "                output.append(['m',1,x,y,0,0,0,0])\n",
    "                last_key = \"M\"\n",
    "            elif last_key == 'l':\n",
    "                x,y = list(map(float,key.split(',')))\n",
    "                output.append(['l',0,x,y,0,0,0,0])\n",
    "                last_key = \"l\"\n",
    "            elif last_key == 'L':\n",
    "                x,y = list(map(float,key.split(',')))\n",
    "                x = x - start[0] + offset[0]\n",
    "                y = y - start[1] + offset[1]\n",
    "                output.append(['l',1,x,y,0,0,0,0])\n",
    "                last_key = \"L\"\n",
    "            elif last_key == 'h':\n",
    "                x = float(key)\n",
    "                output.append(['l',0,x,0,0,0,0,0]) #l is ententionally put here to minimize the # of commands \n",
    "                last_key = \"h\"\n",
    "            elif last_key == 'H':\n",
    "                x = float(key)\n",
    "                x = x - start[0] + offset[0]\n",
    "                output.append(['l',1,x,0,0,0,0,0]) #l is ententionally put here to minimize the # of commands\n",
    "                last_key = \"H\"\n",
    "            elif last_key == 'v':\n",
    "                y = float(key)\n",
    "                output.append(['l',0,0,y,0,0,0,0]) #l is ententionally put here to minimize the # of commands\n",
    "                last_key = \"v\"\n",
    "            elif last_key == 'V':\n",
    "                y = float(key)\n",
    "                y = y - start[1] + offset[1]\n",
    "                output.append(['l',1,0,y,0,0,0,0]) #l is ententionally put here to minimize the # of commands\n",
    "                last_key = \"V\"\n",
    "            else:\n",
    "                print(\"Undefined propagated key\",key,last_key)\n",
    "    return np.array(output,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior to running the function, one-hot encoded values should be brough back to letters for simplicity! \n",
    "def generate_path(commands,path=''):\n",
    "    for command in commands:\n",
    "        if command[0] == 'm':\n",
    "            if command[1] == 0:\n",
    "                path += 'm ' + str(command[2]) + ',' + str(command[3]) + ' '\n",
    "            elif command[1] == 1:\n",
    "                path += 'M ' + str(command[2]) + ',' + str(command[3]) + ' '\n",
    "            else:\n",
    "                print('Unknown state')\n",
    "        elif command[0] == 'c':\n",
    "            if command[1] == 0:\n",
    "                path += 'c ' + str(command[2]) + ',' + str(command[3]) + ' ' + str(command[4]) + ',' + str(command[5])  + ' ' + str(command[6]) + ',' + str(command[7]) + ' '\n",
    "            elif command[1] == 1:\n",
    "                path += 'C ' + str(command[2]) + ',' + str(command[3]) + ' ' + str(command[4]) + ',' + str(command[5])  + ' ' + str(command[6]) + ',' + str(command[7]) + ' '\n",
    "            else:\n",
    "                print('Unknown state')\n",
    "        elif command[0] == 'z':\n",
    "            path += command[0] + ' '\n",
    "        elif command[0] == 'l':\n",
    "            if command[1] == 0:\n",
    "                path += 'l ' + str(command[2]) + ',' + str(command[3]) + ' '\n",
    "            elif command[1] == 1:\n",
    "                path += 'L ' + str(command[2]) + ',' + str(command[3]) + ' '\n",
    "            else:\n",
    "                print('Unknown state')        \n",
    "        else:\n",
    "            print('Unknown command, returning the partial path')\n",
    "    return path[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(matrix):\n",
    "    matrix[:,2:] = ((np.abs(matrix[:,2:]) - np.min(np.abs(matrix[:,2:])))/(np.max(np.abs(matrix[:,2:])) - np.min(np.abs(matrix[:,2:]))))*np.sign(matrix[:,2:])\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(norm_input,angle):\n",
    "    r_matrix = np.array([[np.cos(angle),-np.sin(angle)],[np.sin(angle),np.cos(angle)]])\n",
    "    return np.apply_along_axis(lambda x: np.hstack([x[0:2],np.dot(x[2:4],r_matrix),np.dot(x[4:6],r_matrix),np.dot(x[6:8],r_matrix)]),1,norm_input)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_x(norm_input):\n",
    "    r_matrix = np.array([[1,0],[0,-1]])\n",
    "    return np.apply_along_axis(lambda x: np.hstack([x[0:2],np.dot(x[2:4],r_matrix),np.dot(x[4:6],r_matrix),np.dot(x[6:8],r_matrix)]),1,norm_input)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_y(norm_input):\n",
    "    r_matrix = np.array([[-1,0],[0,1]])\n",
    "    return np.apply_along_axis(lambda x: np.hstack([x[0:2],np.dot(x[2:4],r_matrix),np.dot(x[4:6],r_matrix),np.dot(x[6:8],r_matrix)]),1,norm_input)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_o(norm_input):\n",
    "    r_matrix = np.array([[-1,0],[0,-1]])\n",
    "    return np.apply_along_axis(lambda x: np.hstack([x[0:2],np.dot(x[2:4],r_matrix),np.dot(x[4:6],r_matrix),np.dot(x[6:8],r_matrix)]),1,norm_input)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_xy(norm_input):\n",
    "    r_matrix = np.array([[0,1],[1,0]])\n",
    "    return np.apply_along_axis(lambda x: np.hstack([x[0:2],np.dot(x[2:4],r_matrix),np.dot(x[4:6],r_matrix),np.dot(x[6:8],r_matrix)]),1,norm_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_x(norm_input,scale_x):\n",
    "    r_matrix = np.array([[scale_x,0],[0,1]])\n",
    "    return np.apply_along_axis(lambda x: np.hstack([x[0:2],np.dot(x[2:4],r_matrix),np.dot(x[4:6],r_matrix),np.dot(x[6:8],r_matrix)]),1,norm_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_y(norm_input,scale_y):\n",
    "    r_matrix = np.array([[1,0],[0,scale_y]])\n",
    "    return np.apply_along_axis(lambda x: np.hstack([x[0:2],np.dot(x[2:4],r_matrix),np.dot(x[4:6],r_matrix),np.dot(x[6:8],r_matrix)]),1,norm_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_xy(norm_input,scale_x,scale_y):\n",
    "    r_matrix = np.array([[scale_x,0],[0,scale_y]])\n",
    "    return np.apply_along_axis(lambda x: np.hstack([x[0:2],np.dot(x[2:4],r_matrix),np.dot(x[4:6],r_matrix),np.dot(x[6:8],r_matrix)]),1,norm_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_x(norm_input,scale_x):\n",
    "    r_matrix = np.array([[1,scale_x],[0,1]])\n",
    "    return np.apply_along_axis(lambda x: np.hstack([x[0:2],np.dot(x[2:4],r_matrix),np.dot(x[4:6],r_matrix),np.dot(x[6:8],r_matrix)]),1,norm_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_y(norm_input,scale_y):\n",
    "    r_matrix = np.array([[1,0],[scale_y,1]])\n",
    "    return np.apply_along_axis(lambda x: np.hstack([x[0:2],np.dot(x[2:4],r_matrix),np.dot(x[4:6],r_matrix),np.dot(x[6:8],r_matrix)]),1,norm_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_xy(norm_input,scale_x,scale_y):\n",
    "    r_matrix = np.array([[1,scale_x],[scale_y,1]])\n",
    "    return np.apply_along_axis(lambda x: np.hstack([x[0:2],np.dot(x[2:4],r_matrix),np.dot(x[4:6],r_matrix),np.dot(x[6:8],r_matrix)]),1,norm_input)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_all_flips(norm_output,samples):\n",
    "    #samples.append(flip_x(norm_output))\n",
    "    samples.append(flip_y(norm_output))\n",
    "    samples.append(flip_o(norm_output))\n",
    "    #samples.append(flip_xy(norm_output))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_all_skews(norm_output,num_transform,samples,multiplier):\n",
    "    x_scales = np.random.uniform(-0.7,0.7, num_transform)\n",
    "    y_scales = np.random.uniform(-0.7,0.7, num_transform)\n",
    "    x_scales_2 = np.random.uniform(-0.5,0.5, num_transform) #we could leverage the same x and y, though\n",
    "    y_scales_2 = np.random.uniform(-0.5,0.5, num_transform)\n",
    "    for i in range(num_transform):\n",
    "        skewed = skew_x(norm_output,x_scales[i])\n",
    "        max_move = max(abs(np.min(skewed[:,1:])),np.max(skewed[:,1:]))\n",
    "        #get necessary scaling\n",
    "        skew_scale = multiplier/max_move\n",
    "        if skew_scale < 1:\n",
    "            skewed = scale_xy(skewed,skew_scale,skew_scale)\n",
    "        samples.append(skewed)\n",
    "        skewed = skew_y(norm_output,y_scales[i])\n",
    "        max_move = max(abs(np.min(skewed[:,1:])),np.max(skewed[:,1:]))\n",
    "        #get necessary scaling\n",
    "        skew_scale = multiplier/max_move\n",
    "        if skew_scale < 1:\n",
    "            skewed = scale_xy(skewed,skew_scale,skew_scale)\n",
    "        samples.append(skewed)\n",
    "        skewed = skew_xy(norm_output,x_scales_2[i],y_scales_2[i])\n",
    "        max_move = max(abs(np.min(skewed[:,1:])),np.max(skewed[:,1:]))\n",
    "        #get necessary scaling\n",
    "        skew_scale = multiplier/max_move\n",
    "        if skew_scale < 1:\n",
    "            skewed = scale_xy(skewed,skew_scale,skew_scale)\n",
    "        samples.append(skewed)     \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_all_scales(norm_output,num_transform,samples,multiplier):\n",
    "    x_scales = np.random.uniform(0.5,1, num_transform)\n",
    "    y_scales = np.random.uniform(0.5,1, num_transform)\n",
    "    x_scales_2 = np.random.uniform(0.5,1, num_transform) #we could leverage the same x and y, though\n",
    "    y_scales_2 = np.random.uniform(0.5,1, num_transform)\n",
    "    for i in range(num_transform):\n",
    "        scaled = scale_x(norm_output,x_scales[i])\n",
    "        samples.append(scaled)\n",
    "        samples = apply_all_skews(scaled,num_transform,samples,multiplier)\n",
    "        scaled = scale_y(norm_output,y_scales[i])\n",
    "        samples.append(scaled)\n",
    "        samples = apply_all_skews(scaled,num_transform,samples,multiplier)\n",
    "        scaled = scale_xy(norm_output,x_scales_2[i],y_scales_2[i])\n",
    "        samples.append(scaled)\n",
    "        samples = apply_all_skews(scaled,num_transform,samples,multiplier)        \n",
    "    return samples    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotate,flip_x,flip_y,flip_o,flip_xy,scale_x,scale_y,scale_xy,skew_x,skew_y,skew_xy\n",
    "def random_transform(norm_output,num_transform,samples,multiplier):\n",
    "    #We wanna combine transformations as well, flip in all possible ways, rotate, scale, skew, then flip again\n",
    "    #Flip the original image,\n",
    "    samples.append(norm_output)\n",
    "    return samples\n",
    "    samples = apply_all_flips(norm_output,samples)\n",
    "    sample_len = len(samples)\n",
    "    for i in range(sample_len):\n",
    "        #generate random angles (-180,180)\n",
    "        angles = random.sample(range(0,1), 1) #updated \n",
    "        for angle in angles:\n",
    "            rotated = rotate(samples[i],angle)\n",
    "            #pass the multiplier here, get the max after rotation \n",
    "            max_move = max(abs(np.min(rotated[:,1:])),np.max(rotated[:,1:]))\n",
    "            #get necessary scaling\n",
    "            rotation_scale = multiplier/max_move\n",
    "            if rotation_scale < 1:\n",
    "                rotated = scale_xy(rotated,rotation_scale,rotation_scale)\n",
    "            samples.append(rotated)\n",
    "            samples = apply_all_scales(rotated,num_transform,samples,multiplier)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_fill(sample,length,split_multiplier):\n",
    "    if len(sample) < length:\n",
    "        return np.expand_dims(np.vstack((sample,np.zeros((length-len(sample),sample.shape[1])))),axis=0)\n",
    "    elif len(sample) > length:\n",
    "        n_splits = int((len(sample)/length-1)*split_multiplier)+1\n",
    "        split_points = random.sample(range(len(sample)-length),n_splits)\n",
    "        subsamples = []\n",
    "        for point in split_points:\n",
    "            subsamples.append(sample[point:point+length])\n",
    "        return np.array(subsamples)\n",
    "    else:\n",
    "        return np.expand_dims(sample,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = minidom.parse(\"Minisample/flowers.svg\")  # parseString also exists geometrical_4\n",
    "square_path = [path.getAttribute('d') for path\n",
    "                in doc.getElementsByTagName('path')]\n",
    "doc.unlink()\n",
    "square_matrix = parse_path(square_path[4].split(),output=[],offset=[0,0],first_run=True)\n",
    "square_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformed_samples = random_transform(square_matrix,10,[],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_6 = generate_path(scale_x(small_norm[:],0.5))\n",
    "path_6 = generate_path(rotate(flip_x(square_matrix),0))\n",
    "dwg_6 = svgwrite.Drawing('test_6.svg') #,size = (\"247\", \"148\")\n",
    "#dwg_4.viewbox(0,0,1000,100)\n",
    "dwg_6.add(dwg_6.path( d=path_6,\n",
    "    transform=\"scale(0.9), matrix(1.3333333,0,0,-1.3333333,100,100)\"))\n",
    "#))\n",
    "dwg_6.save()\n",
    "SVG('test_6.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_results = np.vstack(transformed_samples).reshape(-1,10,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(min_length=5,seq_length=57,multiplier=50,discrete=False,num_transform=2):\n",
    "    # Spacers will go with all 0s\n",
    "    # We wanna one hot encode the first column before forming the last matrix\n",
    "    all_results = []\n",
    "    for filename in os.listdir('Minisample'):\n",
    "        doc = minidom.parse(os.path.join('Minisample',filename))\n",
    "        path_strings = [path.getAttribute('d') for path\n",
    "                in doc.getElementsByTagName('path')]\n",
    "        doc.unlink()\n",
    "        parsed = [] \n",
    "        for i,path in enumerate(path_strings):\n",
    "            try:\n",
    "                parsed_matrix = parse_path(path.split(),output=[],offset=[0,0],first_run=True)\n",
    "            except:\n",
    "                print(\"parse error is in\",i)\n",
    "            if len(parsed_matrix) < min_length:\n",
    "                continue\n",
    "            norm_matrix = normalize(parsed_matrix)\n",
    "            norm_matrix[:,2:] = norm_matrix[:,2:]*multiplier\n",
    "            #do the transformations\n",
    "            transformed_samples = random_transform(norm_matrix,num_transform,[],multiplier)\n",
    "            #fill and cut\n",
    "            for sample in transformed_samples:\n",
    "                #sample = flip_x(sample)\n",
    "                if discrete:\n",
    "                    sample[:,2:] = np.apply_along_axis(lambda x: list(map(int,x)),1,sample[:,2:])\n",
    "                subsamples = split_and_fill(sample,seq_length,2)\n",
    "                parsed.append(subsamples)\n",
    "        #print(parsed[0].shape,parsed[1].shape)\n",
    "        all_results.append(np.vstack(parsed))\n",
    "        try:\n",
    "            print(filename,\":\",np.min(list(map(len,parsed))),np.max(list(map(len,parsed))),np.median(list(map(len,parsed))))\n",
    "        except:\n",
    "            print(parsed)\n",
    "        break\n",
    "    return np.vstack(all_results)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = prepare_data(num_transform=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cov = all_results[:,:,2:].reshape((-1,6))\n",
    "cov = np.cov(test_cov.T.astype('float'))\n",
    "cov = torch.tensor(cov,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder()\n",
    "labels = label_enc.fit_transform(list(all_results[:,:,0].reshape(-1, 1).flatten()))\n",
    "labels = np.expand_dims(labels,axis=1) #do we need this one?\n",
    "labels.shape\n",
    "labels = labels.reshape((-1,57))\n",
    "all_results[:,:,0] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the one hot encoding part\n",
    "#norm_output = all_results[0]\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "encodings = enc.fit_transform(all_results[:,:,0].reshape(-1, 1)).toarray()\n",
    "encoded_values = np.hstack((encodings,all_results[:,:,1:].reshape(encodings.shape[0],all_results.shape[2]-1)))\n",
    "encoded_values = encoded_values.reshape((all_results.shape[0],all_results.shape[1],encoded_values.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_results.shape,encoded_values.shape) # should be (54375, 100, 8) (54375, 100, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(encoded_values),np.max(encoded_values)) #We don't need scaling under 50 anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda0 = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = encoded_values[:,:-1,:]\n",
    "print(x.shape) #(54375, 99, 12)\n",
    "x = torch.tensor(x.astype('float'),dtype=torch.float,device=cuda0) #,device=cuda0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = all_results[:,1:,:]\n",
    "print(y.shape) #(54375, 99, 8)\n",
    "y = torch.tensor(y.astype('float'),dtype=torch.float,device=cuda0) #,device=cuda0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batches = torch.split(x,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batches = torch.split(y,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMArtist(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, class_dim, mix_k, num_layers=2,dropout=0.1): #, dropout=0.1\n",
    "        super(LSTMArtist, self).__init__()\n",
    "        \n",
    "        #self.cov = torch.eye(6)\n",
    "        #self.cov.requires_grad = True\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim,num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.hidden2method = nn.Linear(hidden_dim, mix_k*class_dim)\n",
    "        self.hidden2absolute = nn.Linear(hidden_dim, mix_k)\n",
    "        #self.hidden2coordinates = nn.Linear(hidden_dim, 6)\n",
    "        \n",
    "        self.linear_mu = nn.Linear(hidden_dim,mix_k*6)\n",
    "        self.linear_sigmasq = nn.Linear(hidden_dim,mix_k*36)\n",
    "        self.linear_mix = nn.Linear(hidden_dim,mix_k)\n",
    "        \n",
    "        self.activation = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        method = self.softmax(self.hidden2method(lstm_out))\n",
    "        absolute = self.sigmoid(self.hidden2absolute(lstm_out)).squeeze()\n",
    "        #coordinates = self.hidden2coordinates(lstm_out)\n",
    "        coordinates_mu = self.linear_mu(lstm_out)\n",
    "        coordinates_sigmasq = torch.exp(self.linear_sigmasq(lstm_out)) #torch.exp self.relu\n",
    "        coordinates_mix = self.softmax(self.linear_mix(lstm_out))\n",
    "        return (method,absolute,coordinates_mu,coordinates_sigmasq,coordinates_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(x, u, sigmasq):\n",
    "    # NOTE: we could use the new `torch.distributions` package for this now\n",
    "    #print((-1/(2*sigmasq))* torch.norm((x-mu), 2, 2)**2)\n",
    "    #print(torch.exp((-1/(2*sigmasq))* torch.norm((x-mu), 2, 2)**2))\n",
    "    #get the multivariate function here and use the diagonal matrix\n",
    "    k = x.shape[-1]\n",
    "    #cov = torch.diag_embed(sigmasq)\n",
    "    cov = sigmasq.reshape((sigmasq.shape[0],sigmasq.shape[1],6,6))\n",
    "    #male the matrix positive-definite\n",
    "    cov = torch.matmul(cov,cov.permute(0,1,3,2))\n",
    "    #print(cov.shape)\n",
    "    cov = cov + torch.eye(6,device=cuda0).repeat(x.shape[0],x.shape[1],1,1)\n",
    "\n",
    "    #print(cov)\n",
    "    t1 = (2 * np.pi)**k\n",
    "    t2 = torch.det(cov)\n",
    "    t3 = 1.0 / torch.sqrt(t1 * t2)  # scalar \n",
    "    t4 = (x - u)\n",
    "    #print(\"t1:\",t1)\n",
    "    #print(\"t2:\",t2)\n",
    "    #print(\"t3:\",t1 * t2)\n",
    "    #print(\"t4:\",t4)\n",
    "    t5 = torch.inverse(cov)\n",
    "    #print(\"t5:\",t5)\n",
    "    t7 = -0.5 * torch.diagonal(torch.matmul(torch.diagonal(torch.matmul(t4.reshape((-1,k)),t5.reshape(-1,k,k)),dim1=0,dim2=1).T,t4.reshape((-1,k)).T),dim1=0,dim2=1).reshape((t4.shape[0:2]))\n",
    "    pdf = t3 * torch.exp(torch.min(torch.tensor(50.0).to(cuda0),torch.max(torch.tensor(-50.0).to(cuda0),t7))) \n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(method,absolute,coordinates_mu,coordinates_sigmasq,coordinates_mix,t,k,y,ce_loss,bce_loss,methods_n):\n",
    "    method = method.permute((0,2,1))\n",
    "    #print(out_cordinates.shape)\n",
    "    y_method = y[:,:,0].long()\n",
    "    y_absolute = y[:,:,1]\n",
    "    #y_coordinates = y[:,:,2:8]\n",
    "    #loss_coordinates = mse_loss(coordinates,y_coordinates)\n",
    "    #Get the -log likelihood\n",
    "    #losses = Variable(torch.zeros(y.shape[0:2])) #.to(cuda0)\n",
    "    losses_method = torch.zeros(y.shape[0:2],device = cuda0)\n",
    "    losses_absolute = torch.zeros(y.shape[0:2],device = cuda0)\n",
    "    losses = torch.zeros(y.shape[0:2],device = cuda0)\n",
    "    \n",
    "    for i in range(k):  # To Do: put k versions for method and absolute, add loss proportionally likelihood\n",
    "        losses_method += coordinates_mix[:,:,i] * ce_loss(method[:,i*methods_n:(i+1)*methods_n,:],y_method)\n",
    "        losses_absolute += coordinates_mix[:,:,i] * bce_loss(absolute[:,:,i],y_absolute)\n",
    "        likelihood_z_x = gaussian_pdf(y[:,:,2:], coordinates_mu[:,:,i*t:(i+1)*t], coordinates_sigmasq[:,:, i*36:(i+1)*36])\n",
    "        #print(likelihood_z_x)\n",
    "        losses += coordinates_mix[:,:,i] * likelihood_z_x\n",
    "    #print(torch.sum(losses_method),torch.sum(losses_absolute),torch.mean(-(torch.log(losses))))\n",
    "    return (torch.mean(losses_method) + torch.mean(losses_absolute) + torch.mean(-(torch.log(losses))),losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30\n",
    "methods_n =5 \n",
    "model = LSTMArtist(12,400,methods_n,k,dropout=0.8).to(cuda0) #.to(cuda0) ,dropout=0.9\n",
    "##################\n",
    "ce_loss = nn.CrossEntropyLoss() # weight=weights, reduction = 'sum', idea - calciulate the weights based on frequency - less frequent get more weight\n",
    "bce_loss = nn.BCELoss()\n",
    "#mse_loss = nn.MSELoss()\n",
    "lr = 0.5 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "#################\n",
    "for epoch in range(20000):\n",
    "    if epoch % 1000 == 0:\n",
    "        print(\"Running epoch\",epoch)\n",
    "    total_loss = 0\n",
    "    for i,batch in enumerate(x_batches):\n",
    "        optimizer.zero_grad()\n",
    "        method,absolute,coordinates_mu,coordinates_sigmasq,coordinates_mix = model(batch)\n",
    "        #print(coordinates_sigmasq)\n",
    "        loss_sum,losses = calculate_loss(method,absolute,coordinates_mu,coordinates_sigmasq,coordinates_mix,6,k,y_batches[i],ce_loss,bce_loss,methods_n)\n",
    "        #print(\">>>>>>>>>>>>>>>>>>>\",losses)\n",
    "        loss_sum.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1) #what param to set here? (grads are exploding without cliping)\n",
    "        optimizer.step()\n",
    "        #print(output.size())\n",
    "        total_loss += loss_sum.item()\n",
    "    if epoch % 1000 == 0:\n",
    "        print(total_loss) #with 10 epochs 7720 2.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_MDM_v1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_vector = x[:1,:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample(method,absolute,coordinates_mu,coordinates_sigmasq,coordinates_mix,label_enc,onehot_enc):\n",
    "    with torch.no_grad():\n",
    "        mix_dist = Categorical(coordinates_mix[0,0,:])\n",
    "        #print(coordinates_mix[0,0,:])\n",
    "        mix_index = mix_dist.sample()\n",
    "        #print(absolute.shape)\n",
    "        method = method[:,:,mix_index*5:(mix_index+1)*5].cpu()\n",
    "        absolute = absolute[mix_index].cpu()\n",
    "        coordinates_mu = coordinates_mu.cpu()\n",
    "        coordinates_sigmasq = coordinates_sigmasq.cpu()\n",
    "        coordinates_mix = coordinates_mix.cpu()\n",
    "        _,key = torch.max(method,2)\n",
    "        str_key = [label_enc.inverse_transform(key)]\n",
    "        #key = np.expand_dims(ey[0],0) #just to awoid a pesky warning, othewise don't needed\n",
    "        onehot_key = onehot_enc.transform(key).toarray()\n",
    "        absolute = [[torch.round(absolute)]]\n",
    "        #get the mix component\n",
    "        #mix_index = np.random.choice(list(range(k)),1, p=coordinates_mix[0,0,:])\n",
    "        #print(coordinates_mix[0,0,:])\n",
    "        \n",
    "        mu = coordinates_mu[0,0,mix_index*6:(mix_index+1)*6]\n",
    "        #print(mu)\n",
    "        sigma = torch.sqrt(coordinates_sigmasq[0,0,mix_index])   \n",
    "        #dist = Normal(mu, sigma) #sigma torch.tensor([0.000001])\n",
    "        #cov = torch.eye(6)*coordinates_sigmasq[0,0,mix_index*6:(mix_index+1)*6]\n",
    "        #print(coordinates_sigmasq.shape)\n",
    "        cov = coordinates_sigmasq[0,0,mix_index*36:(mix_index+1)*36].reshape((6,6))\n",
    "        #make the matrix positive-definite\n",
    "        cov = torch.matmul(cov,cov.T)\n",
    "        cov = cov + torch.eye(6)\n",
    "\n",
    "        #print(cov)\n",
    "        dist = MultivariateNormal(mu,cov.float())\n",
    "        coordinates = dist.sample()\n",
    "        #print(str_key,absolute,coordinates)\n",
    "        return (np.concatenate((str_key,absolute,coordinates.reshape((1,6))),axis=1),np.concatenate((onehot_key,absolute,coordinates.reshape((1,6))),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the picture from the trained model\n",
    "def generate_vectors(model,start_vector,iterations,label_enc,onehot_enc):\n",
    "    vectors = [['m',0,0,0,0,0,0,0]]\n",
    "    input_vecs = start_vector\n",
    "    method,absolute,coordinates_mu,coordinates_sigmasq,coordinates_mix = model(input_vecs)\n",
    "    #print(coordinates_mu)\n",
    "    #print(\"-------------\")\n",
    "    #print(coordinates_mix)\n",
    "    vector,next_input = random_sample(method,absolute,coordinates_mu,coordinates_sigmasq,coordinates_mix,label_enc,onehot_enc)\n",
    "    vectors.append(vector)\n",
    "    input_vecs = torch.cat((input_vecs,torch.tensor(np.expand_dims(next_input,0).astype('float'),dtype=torch.float,device=cuda0)),1)\n",
    "    #print(\">>>\",input_vecs)\n",
    "    for i in range(iterations):\n",
    "        method,absolute,coordinates_mu,coordinates_sigmasq,coordinates_mix = model(input_vecs)\n",
    "        #print(\">>>>>>>>>>\",method,absolute,coordinates_mu,coordinates_sigmasq,coordinates_mix)\n",
    "        vector,next_input = random_sample(method[:,-1:,:],absolute[-1],coordinates_mu[:,-1:,:],coordinates_sigmasq[:,-1:,:],coordinates_mix[:,-1:,:],label_enc,onehot_enc)\n",
    "        vectors.append(vector)\n",
    "        input_vecs = torch.cat((input_vecs,torch.tensor(np.expand_dims(next_input,0).astype('float'),dtype=torch.float,device=cuda0)),1)\n",
    "        #print(input_vecs)\n",
    "    return np.vstack(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = generate_vectors(model,start_vector,57,label_enc,enc)\n",
    "vectors = vectors.astype('object')\n",
    "vectors[:,1] = vectors[:,1].astype('float')\n",
    "vectors[:,2] = vectors[:,2].astype('float')\n",
    "vectors[:,3] = vectors[:,3].astype('float')\n",
    "vectors[:,4] = vectors[:,4].astype('float')\n",
    "vectors[:,5] = vectors[:,5].astype('float')\n",
    "vectors[:,6] = vectors[:,6].astype('float')\n",
    "vectors[:,7] = vectors[:,7].astype('float')\n",
    "#vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_7 = generate_path(vectors)\n",
    "dwg_7 = svgwrite.Drawing('test_180.svg') #,size = (\"247\", \"148\")\n",
    "#dwg_4.viewbox(0,0,1000,100)\n",
    "dwg_7.add(dwg_7.path( d=path_7,\n",
    "    transform=\"scale(1), matrix(1.3333333,0,0,-1.3333333,100,100)\"))\n",
    "#))\n",
    "dwg_7.save()\n",
    "SVG('test_180.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
