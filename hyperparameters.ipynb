{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.bernoulli import Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mushrooms.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[:,0:1]\n",
    "x = df[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y_enc = LabelEncoder()\n",
    "x_encoded = x_enc.fit_transform(x).toarray()\n",
    "y_encoded = np.expand_dims(y_enc.fit_transform(y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_encoded.shape,y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#better to randomly pick the test sample\n",
    "x_train = torch.split(torch.tensor(x_encoded[:4062,:]).float(),16)\n",
    "y_train = torch.split(torch.tensor(y_encoded[:4062,:]).float(),16)\n",
    "x_test = torch.split(torch.tensor(x_encoded[4062:,:]).float(),16)\n",
    "y_test = torch.split(torch.tensor(y_encoded[4062:,:]).float(),16)\n",
    "#print(x_train.shape, y_train.shape,x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoTuning(nn.Module):\n",
    "\n",
    "    def __init__(self): #, dropout=0.1\n",
    "        super(AutoTuning, self).__init__()\n",
    "        self.layer1 = nn.parameter.Parameter(torch.empty((117,1000),requires_grad=True))\n",
    "        torch.nn.init.xavier_uniform_(self.layer1,gain=nn.init.calculate_gain('relu'))\n",
    "        self.b1 = nn.parameter.Parameter(torch.zeros((1, 1000), requires_grad=True))\n",
    "        self.layer2 = nn.parameter.Parameter(torch.empty((1000,1),requires_grad=True))\n",
    "        torch.nn.init.xavier_uniform_(self.layer2,gain=nn.init.calculate_gain('sigmoid'))\n",
    "        self.b2 = nn.parameter.Parameter(torch.zeros((1),requires_grad=True))\n",
    "        \n",
    "        self.parameter_matrix = torch.empty((117,1000),requires_grad=True)\n",
    "        torch.nn.init.xavier_uniform_(self.parameter_matrix,gain=nn.init.calculate_gain('relu'))\n",
    "        print(torch.max(self.parameter_matrix))\n",
    "        self.parameter_matrix = nn.parameter.Parameter(self.parameter_matrix - 0.1035) #-0.1035, 4\n",
    "        \n",
    "    def forward(self,x,x_test,print_stat):\n",
    "        binary_params = torch.tanh(self.parameter_matrix) + (torch.relu(torch.sign(self.parameter_matrix)) - torch.tanh(self.parameter_matrix)).detach()\n",
    "        #binary_params = torch.sign(self.parameter_matrix)\n",
    "        #binary_params = Bernoulli(torch.sigmoid(self.parameter_matrix)).sample().requires_grad_()\n",
    "        out1 = torch.relu(torch.mm(x,self.layer1*binary_params.detach()) + self.b1)\n",
    "        out2 = torch.sigmoid(torch.mm(out1,self.layer2) + self.b2)\n",
    "        \n",
    "        test1 = torch.relu(torch.mm(x_test,self.layer1.detach()*binary_params) + self.b1.detach())\n",
    "        test2 = torch.sigmoid(torch.mm(test1,self.layer2.detach()) + self.b2.detach())\n",
    "        if print_stat:\n",
    "            with torch.no_grad():\n",
    "                print(torch.sum(binary_params))\n",
    "        return out2,test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoTuning()\n",
    "bce_loss = nn.BCELoss()\n",
    "lr = 0.5 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "test_prec = 0 \n",
    "prec_counter = 0\n",
    "prec_limit = 3\n",
    "for epoch in range(10):\n",
    "    for i,x_batch in enumerate(x_train):\n",
    "        optimizer.zero_grad()\n",
    "        out,out_test = model(x_batch,x_test[i],True)\n",
    "        loss = bce_loss(out,y_train[i])\n",
    "        loss_test = bce_loss(out_test,y_test[i])\n",
    "        print(loss.item(),loss_test.item())\n",
    "        loss.backward() #retain_graph=True\n",
    "        loss_test.backward()\n",
    "        optimizer.step()\n",
    "    #new_test_prec = torch.sum((model(x_train,x_test,False)[1]>0.5).int()==y_test)/len(y_test)\n",
    "    #print(epoch,loss.item(),new_test_prec)\n",
    "    #if new_test_prec < test_prec:\n",
    "    #    prec_counter += 1\n",
    "    #    if prec_counter > prec_limit:\n",
    "    #        #break\n",
    "    #        pass\n",
    "    #else:\n",
    "        test_prec = new_test_prec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.randn((20,10))\n",
    "t2 = torch.randn((10,2))\n",
    "b1 = torch.ones((1,2))\n",
    "torch.mm(t1,t2) + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tanh(torch.tensor(5.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = nn.parameter.Parameter(torch.empty((117,100)),requires_grad = True)\n",
    "torch.nn.init.xavier_uniform_(layer1,gain=nn.init.calculate_gain('relu'))\n",
    "#layer1 = layer1 - 0.\n",
    "print(torch.sum(torch.relu(torch.sign(layer1))))\n",
    "torch.sum(torch.relu(layer1))\n",
    "test_copy = layer1.detach().clone()\n",
    "layer1 * test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_binary = Bernoulli(torch.sigmoid(torch.randn((10,10)))).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(torch.randn((10,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
